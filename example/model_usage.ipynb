{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf2216",
   "metadata": {},
   "source": [
    "# bioimageio.core usage examples\n",
    "\n",
    "Checkout [load_model_and_create_your_own.ipynb](https://github.com/bioimage-io/spec-bioimage-io/blob/main/example/) for examples on model creation, loading and inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    %pip install bioimageio.core torch onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74613461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for showing multiple images in napari\n",
    "from bioimageio.core import Tensor\n",
    "from bioimageio.spec.utils import download, load_array\n",
    "from typing import Any, Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "except ImportError:\n",
    "\n",
    "    def show_images(images: Dict[str, Union[Tensor, NDArray[Any], Path]]):\n",
    "        for name, im in images.items():\n",
    "            if isinstance(im, Path):\n",
    "                im = imageio.imread(im)\n",
    "            elif isinstance(im, Tensor):\n",
    "                im = im.data\n",
    "            print(f\"{name}: {im.shape}\")\n",
    "\n",
    "else:\n",
    "    def show_images(images: Dict[str, Union[Tensor, NDArray[Any], Path]]):\n",
    "        v = napari.Viewer()\n",
    "        for name, im in images.items():\n",
    "            if isinstance(im, Path):\n",
    "                im = imageio.imread(im)\n",
    "            elif isinstance(im, Tensor):\n",
    "                im = im.data\n",
    "            print(f\"napari viewer: adding {name}\")\n",
    "            v.add_image(im, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2deb81f",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "\n",
    "We will use a model that predicts boundaries in images of plant cells [kaggle nucles segmentation challenge](https://www.kaggle.com/c/data-science-bowl-2018).\n",
    "Find the model on bioimage.io here: [\"affable-shark](https://bioimage.io/#/?id=10.5281%2Fzenodo.5764892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec import load_description\n",
    "\n",
    "model = load_description(\"affable-shark/draft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de51dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model alternative\n",
    "from bioimageio.spec import load_description\n",
    "\n",
    "model = load_description(\"emotional-cricket/draft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46da8c",
   "metadata": {},
   "source": [
    "Let's briefly checkout the validation summary created upon loading the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce884f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validation_summary.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function 'test_model' from 'bioimageio.core.resource_tests' can be used to fully test the model,\n",
    "# including running prediction for the test input(s) and checking that they agree with the test output(s)\n",
    "# before using a model, it is recommended to check that it properly works with this function\n",
    "# 'test_model' returns a dict with 'status'='passed'/'failed' and more detailed information\n",
    "from bioimageio.core import test_model\n",
    "\n",
    "test_summary = test_model(model)\n",
    "test_summary.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c75014",
   "metadata": {},
   "source": [
    "## Prediction with the model\n",
    "\n",
    "`bioimageio.core` implements functionality to run prediction with models desribed in the `bioimage.io` format.\n",
    "This includes functions to run prediction on `numpy.ndarray`s/`xarray.DataArrays` as input and convenience functions to run predictions for images stored on disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example image for this model, which is stored in numpy file format.\n",
    "from bioimageio.spec.utils import load_array\n",
    "from bioimageio.spec.model import v0_5\n",
    "\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "input_image = load_array(model.inputs[0].test_tensor)\n",
    "print(f\"array shape: {input_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import Sample, Tensor\n",
    "\n",
    "# Create a `Tensor` (light wrapper around an `xarray.DataArray`) from the test input image.\n",
    "# `bioimageio.core.Tensors/xarray.DataArrays` are like numpy arrays, but they have annotated axes.\n",
    "# The axes are used to validate that the axes of the input image match the axes expected by a model.\n",
    "test_input_tensor = Tensor.from_numpy(input_image, dims=model.inputs[0].axes)\n",
    "\n",
    "# print the axis annotations ('dims') and the shape of the input array\n",
    "print(f\"tensor shape: {test_input_tensor.tagged_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can create a sample --- a collection of tensors.\n",
    "# In this case our model only has one input, but for models with multiple inputs a `Sample` includes a tensor for each input.\n",
    "sample = Sample(members={\"raw\": test_input_tensor}, stat=None, id=\"sample-from-numpy\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut: helper function `create_sample_for_model` to create a sample for a given model directly\n",
    "\n",
    "from bioimageio.core.digest_spec import create_sample_for_model\n",
    "from bioimageio.spec.utils import download\n",
    "\n",
    "input_paths = {ipt.id: download(ipt.test_tensor).path for ipt in model.inputs}\n",
    "print(f\"input paths: {input_paths}\")\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "sample = create_sample_for_model(\n",
    "    model=model, inputs=input_paths, sample_id=\"my_demo_sample\"\n",
    ")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff89c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut: get test input sample for a given model\n",
    "from bioimageio.core.digest_spec import get_test_inputs\n",
    "\n",
    "test_sample = get_test_inputs(model)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import create_prediction_pipeline\n",
    "\n",
    "# Next, create a 'prediction_pipeline'. The prediction_pipeline is used to run prediction with a given model.\n",
    "# This means it applies the preprocessing, runs inference with the model and applies the postprocessing.\n",
    "\n",
    "# The 'devices' argument can be used to specify which device(s) to use for inference with the model.\n",
    "# Hence it can be used to specify whether to use the cpu, a single gpu or multiple gpus (not implemented yet).\n",
    "# By default (devices=None) a gpu will be used if available and otherwise the cpu will be used.\n",
    "devices = None\n",
    "\n",
    "# The 'weight_format' argument can be used to specify which weight format available in the model to use.\n",
    "# By default (weight_format=None) the weight format with highest priority (as defined by bioimageio.core) will be used.\n",
    "weight_format = None\n",
    "\n",
    "prediction_pipeline = create_prediction_pipeline(\n",
    "    model, devices=devices, weight_format=weight_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c73742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prediction pipeline to run prediction for the image we loaded before.\n",
    "# The prediction pipeline returns a `Sample` object.\n",
    "prediction: Sample = prediction_pipeline.predict_sample_without_blocking(sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images({**sample.members, **prediction.members})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b102c2",
   "metadata": {},
   "source": [
    "there are convenience functions `predict` and `predict_many` that can be used to predict images without explicit creation of a `PredictionPipeline`... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import predict  # , predict_many\n",
    "\n",
    "predict(model=model, inputs=sample)\n",
    "# predict_many(model=model, inputs=[sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
